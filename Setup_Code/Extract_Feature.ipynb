{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9973bc01",
   "metadata": {
    "id": "fCFX0aYBa86h"
   },
   "source": [
    "# Features Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c623a591",
   "metadata": {
    "id": "C68OPGkwz6is"
   },
   "source": [
    "#เเก้ PATH ตรงนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed257c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skimage.feature import hog\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import cv2, glob, random, math, numpy as np, dlib, itertools\n",
    "import os\n",
    "import random\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "image_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a302f5a",
   "metadata": {
    "id": "IWR2ZlJtbA5_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def list_images(basePath, contains=None):\n",
    "    return list_files(basePath, validExts=image_types, contains=contains)\n",
    "\n",
    "\n",
    "def list_files(basePath, validExts=None, contains=None):\n",
    "    # loop over the directory structure\n",
    "    for (rootDir, dirNames, filenames) in os.walk(basePath):\n",
    "        # loop over the filenames in the current directory\n",
    "        for filename in filenames:\n",
    "            # if the contains string is not none and the filename does not contain\n",
    "            # the supplied string, then ignore the file\n",
    "            if contains is not None and filename.find(contains) == -1:\n",
    "                continue\n",
    "\n",
    "            # determine the file extension of the current file\n",
    "            ext = filename[filename.rfind(\".\"):].lower()\n",
    "\n",
    "            # check to see if the file is an image and should be processed\n",
    "            if validExts is None or ext.endswith(validExts):\n",
    "                # construct the path to the image and yield it\n",
    "                imagePath = os.path.join(rootDir, filename)\n",
    "                yield imagePath\n",
    "\n",
    "imagePaths = list(list_images(r'C:\\Users\\thanawin\\Desktop\\data\\final_detect\\train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20efdc",
   "metadata": {
    "id": "he5wnoVukMBK"
   },
   "source": [
    "GET features and labes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "322fe1af",
   "metadata": {
    "id": "QM7uPOKSbObP"
   },
   "outputs": [],
   "source": [
    "def colortogray(im):\n",
    "    image = cv2.imread(im)\n",
    "    imgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    return imgray\n",
    "\n",
    "def feat_lab_HOG(imagePaths):\n",
    "\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for imagePath in imagePaths:\n",
    "        im = colortogray(imagePath)\n",
    "        \n",
    "        fd1 =  hog(im, orientations=7, pixels_per_cell=(8, 8),cells_per_block=(4, 4),block_norm= 'L2-Hys' ,transform_sqrt = False)\n",
    "\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        labels.append(label)\n",
    "        features.append(fd1)\n",
    "\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    return features,labels\n",
    "\n",
    "def feat_lab_LAND(imagePaths):\n",
    "      features = []\n",
    "      labels = []\n",
    "      for imagePath in imagePaths:\n",
    "        im = colortogray(imagePath)\n",
    "        clahe_image = clahe.apply(im)\n",
    "        landmarks_vectorised = get_landmarks(clahe_image)\n",
    "        if landmarks_vectorised == \"error\":\n",
    "          pass\n",
    "        else:\n",
    "          label = imagePath.split(os.path.sep)[-2]\n",
    "          labels.append(label)\n",
    "          features.append(landmarks_vectorised)\n",
    "      features = np.array(features)\n",
    "      labels = np.array(labels)\n",
    "      return features,labels\n",
    "\n",
    "def feat_lab_LBP(imagePaths):\n",
    "      features = []\n",
    "      labels = []\n",
    "      for imagePath in imagePaths:\n",
    "        im = colortogray(imagePath)\n",
    "        lbp_featured = lbp_feature(im)\n",
    "        if lbp_featured == \"error\":\n",
    "          pass\n",
    "        else:\n",
    "          label = imagePath.split(os.path.sep)[-2]\n",
    "          labels.append(label)\n",
    "          features.append(lbp_featured)\n",
    "      features = np.array(features)\n",
    "      labels = np.array(labels)\n",
    "      return features,labels\n",
    "\n",
    "def feat_lab_HLAC(imagePaths):\n",
    "      features = []\n",
    "      labels = []\n",
    "      for imagePath in imagePaths:\n",
    "        im = colortogray(imagePath)\n",
    "        _, img = cv2.threshold(im, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "        hlac_featured = calc_hlac_dev(img)\n",
    "        if hlac_featured == \"error\":\n",
    "          pass\n",
    "        else:\n",
    "          label = imagePath.split(os.path.sep)[-2]\n",
    "          labels.append(label)\n",
    "          features.append(hlac_featured)\n",
    "      features = np.array(features)\n",
    "      labels = np.array(labels)\n",
    "      return features,labels\n",
    "\n",
    "def feat_lab_GABOR(imagePaths):\n",
    "      features = []\n",
    "      labels = []\n",
    "      for imagePath in imagePaths:\n",
    "        im = colortogray(imagePath)\n",
    "        gabor_featured = get_gabor(im)\n",
    "        if gabor_featured == \"error\":\n",
    "          pass\n",
    "        else:\n",
    "          label = imagePath.split(os.path.sep)[-2]\n",
    "          labels.append(label)\n",
    "          features.append(gabor_featured)\n",
    "      features = np.array(features)\n",
    "      labels = np.array(labels)\n",
    "      return features,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f622bd7f",
   "metadata": {
    "id": "BwWMBNwLesJy"
   },
   "outputs": [],
   "source": [
    "def get_landmarks(image):\n",
    "    detections = detector(image, 1)\n",
    "    for k,d in enumerate(detections): #For all detected face instances individually\n",
    "        shape = predictor(image, d) #Draw Facial Landmarks with the predictor class\n",
    "        xlist = []\n",
    "        ylist = []\n",
    "        for i in range(1,68): #Store X and Y coordinates in two lists\n",
    "            xlist.append(float(shape.part(i).x))\n",
    "            ylist.append(float(shape.part(i).y))\n",
    "            \n",
    "        xmean = np.mean(xlist) #Get the mean of both axes to determine centre of gravity\n",
    "        ymean = np.mean(ylist)\n",
    "        xcentral = [(x-xmean) for x in xlist] #get distance between each point and the central point in both axes\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "\n",
    "        if xlist[26] == xlist[29]: #If x-coordinates of the set are the same, the angle is 0, catch to prevent 'divide by 0' error in function\n",
    "            anglenose = 0\n",
    "        else:\n",
    "            anglenose = int(math.atan((ylist[26]-ylist[29])/(xlist[26]-xlist[29]))*180/math.pi)\n",
    "\n",
    "        if anglenose < 0:\n",
    "            anglenose += 90\n",
    "        else:\n",
    "            anglenose -= 90\n",
    "\n",
    "        landmarks_vectorised = []\n",
    "        for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):\n",
    "            landmarks_vectorised.append(x)\n",
    "            landmarks_vectorised.append(y)\n",
    "            meannp = np.asarray((ymean,xmean))\n",
    "            coornp = np.asarray((z,w))\n",
    "            dist = np.linalg.norm(coornp-meannp)\n",
    "            anglerelative = (math.atan((z-ymean)/(w-xmean))*180/math.pi) - anglenose\n",
    "            landmarks_vectorised.append(dist)\n",
    "            landmarks_vectorised.append(anglerelative)\n",
    "\n",
    "    if len(detections) < 1: \n",
    "        landmarks_vectorised = \"error\"\n",
    "    return landmarks_vectorised\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130580f9",
   "metadata": {
    "id": "tPiUdoj9hn79"
   },
   "source": [
    "LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc67e031",
   "metadata": {
    "id": "nu_JjkSWhmoi"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def get_pixel(img, center, x, y):\n",
    "    new_value = 0\n",
    "    try:\n",
    "        if img[x][y] >= center:\n",
    "            new_value = 1\n",
    "    except:\n",
    "        pass\n",
    "    return new_value\n",
    "\n",
    "def lbp_calculated_pixel(img, x, y):\n",
    "    '''\n",
    "\n",
    "     64 | 128 |   1\n",
    "    ----------------\n",
    "     32 |   0 |   2\n",
    "    ----------------\n",
    "     16 |   8 |   4    \n",
    "\n",
    "    '''    \n",
    "    center = img[x][y]\n",
    "    val_ar = []\n",
    "    val_ar.append(get_pixel(img, center, x-1, y+1))     # top_right\n",
    "    val_ar.append(get_pixel(img, center, x, y+1))       # right\n",
    "    val_ar.append(get_pixel(img, center, x+1, y+1))     # bottom_right\n",
    "    val_ar.append(get_pixel(img, center, x+1, y))       # bottom\n",
    "    val_ar.append(get_pixel(img, center, x+1, y-1))     # bottom_left\n",
    "    val_ar.append(get_pixel(img, center, x, y-1))       # left\n",
    "    val_ar.append(get_pixel(img, center, x-1, y-1))     # top_left\n",
    "    val_ar.append(get_pixel(img, center, x-1, y))       # top\n",
    "    \n",
    "    power_val = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "    val = 0\n",
    "    for i in range(len(val_ar)):\n",
    "        val += val_ar[i] * power_val[i]\n",
    "    return val    \n",
    "\n",
    "def show_output(output_list):\n",
    "    output_list_len = len(output_list)\n",
    "    figure = plt.figure()\n",
    "    for i in range(output_list_len):\n",
    "        current_dict = output_list[i]\n",
    "        current_img = current_dict[\"img\"]\n",
    "        current_xlabel = current_dict[\"xlabel\"]\n",
    "        current_ylabel = current_dict[\"ylabel\"]\n",
    "        current_xtick = current_dict[\"xtick\"]\n",
    "        current_ytick = current_dict[\"ytick\"]\n",
    "        current_title = current_dict[\"title\"]\n",
    "        current_type = current_dict[\"type\"]\n",
    "        current_plot = figure.add_subplot(1, output_list_len, i+1)\n",
    "        if current_type == \"gray\":\n",
    "            current_plot.imshow(current_img, cmap = plt.get_cmap('gray'))\n",
    "            current_plot.set_title(current_title)\n",
    "            current_plot.set_xticks(current_xtick)\n",
    "            current_plot.set_yticks(current_ytick)\n",
    "            current_plot.set_xlabel(current_xlabel)\n",
    "            current_plot.set_ylabel(current_ylabel)\n",
    "        elif current_type == \"histogram\":\n",
    "            current_plot.plot(current_img, color = \"black\")\n",
    "            current_plot.set_xlim([0,260])\n",
    "            current_plot.set_title(current_title)\n",
    "            current_plot.set_xlabel(current_xlabel)\n",
    "            current_plot.set_ylabel(current_ylabel)            \n",
    "            ytick_list = [int(i) for i in current_plot.get_yticks()]\n",
    "            current_plot.set_yticklabels(ytick_list,rotation = 90)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def lbp_feature(image):\n",
    "    img_bgr = image\n",
    "    \n",
    "    height, width = img_bgr.shape\n",
    "    #gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_lbp = np.zeros((height, width,3), np.uint8)\n",
    "    for i in range(0, height):\n",
    "        for j in range(0, width):\n",
    "             img_lbp[i, j] = lbp_calculated_pixel(image, i, j)\n",
    "    hist_lbp = cv2.calcHist([img_lbp], [0], None, [256], [0, 256])\n",
    "    return hist_lbp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e538268a",
   "metadata": {
    "id": "r2R5auZRjpNe"
   },
   "source": [
    "HLAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "220d5ee9",
   "metadata": {
    "id": "UTDx6Q6qh8nw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "def calc_chlac_dev(div_data, masks, mask_n):\n",
    "    chlacs = np.array([])\n",
    "    for m, mn in zip(masks, mask_n):\n",
    "        chlacs = np.append(\n",
    "            chlacs, (np.sum(np.sum(np.logical_and(m, div_data), axis=1) == mn))\n",
    "        )\n",
    "    return chlacs\n",
    "\n",
    "\n",
    "# oldถุ version, too slow\n",
    "def calc_chlac(div_data, masks, mask_n):\n",
    "    chlacs = []\n",
    "    for m, mn in zip(masks, mask_n):\n",
    "        logic = np.logical_and(m, div_data)\n",
    "        logic_sum = np.sum(logic, axis=1)\n",
    "        chlacs.append(np.sum(logic_sum == int(mn)))\n",
    "    return np.array(chlacs)\n",
    "\n",
    "\n",
    "def split2boxel(data):\n",
    "    x, y = data[0].shape\n",
    "    d = 3\n",
    "    li = []\n",
    "    # 最外周は外してnp.whereを実行\n",
    "    # np.whereは切り出したndarrayに対して条件に一致するインデックスを返す\n",
    "    idxs_x, idxs_y = np.where(data[1, 1:-1, 1:-1] == 255)\n",
    "    # i, jは切り出すボクセルの左上隅のインデックスを表す\n",
    "    for i, j in zip(idxs_x, idxs_y):\n",
    "        li.append(data[:, i: i + d, j: j + d])\n",
    "    div_data = np.array(li).reshape([len(li), 27]).astype(np.int32)\n",
    "\n",
    "    return div_data\n",
    "\n",
    "\n",
    "# old version, too slow\n",
    "def split2boxel_(data):\n",
    "    x, y = data[0].shape\n",
    "    d = 3\n",
    "    li = []\n",
    "    for i in range(x - 2):\n",
    "        for j in range(y - 2):\n",
    "            if data[1, i + 1, j + 1] != 0:\n",
    "                li.append(data[:, i: i + d, j: j + d])\n",
    "    div_data_ = np.array(li).reshape([len(li), 27]).astype(np.int32)\n",
    "\n",
    "    return div_data_\n",
    "\n",
    "\n",
    "def prepare_masks_chlac(mask_filepath):\n",
    "    data = pd.read_csv(mask_filepath, header=None, index_col=0)\n",
    "    N_mask = data.shape[0]\n",
    "\n",
    "    masks = []\n",
    "    for j in range(N_mask):\n",
    "        mask = np.zeros([3, 3, 3])  # voxel\n",
    "        _ = []\n",
    "        for i in range(3):\n",
    "            if data.iloc[j, i] == \"x\":\n",
    "                _.append([])\n",
    "            elif data.iloc[j, i] != \"x\":\n",
    "                if len(data.iloc[j, i]) == 1:\n",
    "                    _.append([data.iloc[j, i]])\n",
    "                else:\n",
    "                    _.append(data.iloc[j, i].split(\",\"))\n",
    "\n",
    "        for i in range(3):\n",
    "            if len(_[i]) == 0:\n",
    "                continue\n",
    "            for m in _[i]:\n",
    "                if m == \"a\":\n",
    "                    mask[0, i, 0] = 1\n",
    "                elif m == \"b\":\n",
    "                    mask[1, i, 0] = 1\n",
    "                elif m == \"c\":\n",
    "                    mask[2, i, 0] = 1\n",
    "                elif m == \"d\":\n",
    "                    mask[0, i, 1] = 1\n",
    "                elif m == \"e\":\n",
    "                    mask[1, i, 1] = 1\n",
    "                elif m == \"f\":\n",
    "                    mask[2, i, 1] = 1\n",
    "                elif m == \"g\":\n",
    "                    mask[0, i, 2] = 1\n",
    "                elif m == \"h\":\n",
    "                    mask[1, i, 2] = 1\n",
    "                elif m == \"i\":\n",
    "                    mask[2, i, 2] = 1\n",
    "        mask = mask.reshape(mask.shape[0] * mask.shape[1] * mask.shape[2])\n",
    "        masks.append(mask)\n",
    "    masks = np.array(masks)\n",
    "    mask_n = np.array(masks).sum(axis=1)\n",
    "\n",
    "    return masks, mask_n\n",
    "\n",
    "\n",
    "def read_testdata():\n",
    "    imgs = 255 * np.array(\n",
    "        [\n",
    "            [\n",
    "                [1, 0, 1, 1, 0, 1],\n",
    "                [1, 1, 0, 0, 1, 1],\n",
    "                [0, 0, 1, 0, 0, 0],\n",
    "                [1, 1, 1, 1, 1, 0],\n",
    "                [1, 1, 1, 1, 1, 1],\n",
    "                [0, 0, 0, 1, 0, 0],\n",
    "            ],\n",
    "            [\n",
    "                [1, 1, 1, 0, 0, 1],\n",
    "                [1, 1, 1, 0, 0, 1],\n",
    "                [0, 1, 1, 0, 1, 0],\n",
    "                [1, 1, 0, 1, 1, 0],\n",
    "                [1, 1, 1, 0, 0, 0],\n",
    "                [0, 1, 0, 0, 0, 0],\n",
    "            ],\n",
    "            [\n",
    "                [1, 1, 0, 0, 1, 1],\n",
    "                [0, 0, 1, 1, 0, 1],\n",
    "                [0, 1, 0, 1, 0, 1],\n",
    "                [1, 1, 1, 0, 0, 0],\n",
    "                [1, 0, 0, 1, 0, 0],\n",
    "                [0, 1, 1, 0, 1, 1],\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return imgs\n",
    "\n",
    "\n",
    "def calc_hlac_dev(img, dim=3):\n",
    "    masks_origin = [\n",
    "        \"000010000\",\n",
    "        \"000011000\",\n",
    "        \"001010000\",\n",
    "        \"010010000\",\n",
    "        \"100010000\",\n",
    "        \"000111000\",\n",
    "        \"001010100\",\n",
    "        \"010010010\",\n",
    "        \"100010001\",\n",
    "        \"001110000\",\n",
    "        \"010010100\",\n",
    "        \"100010010\",\n",
    "        \"000110001\",\n",
    "        \"000011100\",\n",
    "        \"001010010\",\n",
    "        \"010010001\",\n",
    "        \"100011000\",\n",
    "        \"010110000\",\n",
    "        \"100010100\",\n",
    "        \"000110010\",\n",
    "        \"000010101\",\n",
    "        \"000011010\",\n",
    "        \"001010001\",\n",
    "        \"010011000\",\n",
    "        \"101010000\",\n",
    "    ]\n",
    "    masks = []\n",
    "    masks_n = []\n",
    "\n",
    "    # make masks\n",
    "    for mask_bin in masks_origin:\n",
    "        m = []\n",
    "        s = 0\n",
    "        for ch in mask_bin:\n",
    "            m.append(int(ch))\n",
    "            if int(ch) == 1:\n",
    "                s += 1   \n",
    "                            \n",
    "        masks.append(np.array(m).reshape((3, 3)))\n",
    "        masks_n.append(s)\n",
    "\n",
    "    height, width = img.shape\n",
    "\n",
    "    a = patchify(img, (3, 3))\n",
    "    a = a.reshape(\n",
    "        (height - 2) * (width - 2), 3, 3\n",
    "    )  # (x-2, y-2, 3) -> ((x-2)*(y-2), 3, 3)\n",
    "\n",
    "    ret = []\n",
    "    for mask, n in zip(masks, masks_n):\n",
    "        res = np.logical_and(mask, a)\n",
    "        logic = np.sum(np.sum(res, axis=2), axis=1)\n",
    "        ret.append(np.sum(logic == n))\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def patchify(img, patch_shape):\n",
    "    img = np.ascontiguousarray(img)  # won't make a copy if not needed\n",
    "    X, Y = img.shape\n",
    "    x, y = patch_shape\n",
    "    shape = ((X - x + 1), (Y - y + 1), x, y)  # number of patches, patch_shape\n",
    "    # The right strides can be thought by:\n",
    "    # 1) Thinking of `img` as a chunk of memory in C order\n",
    "    # 2) Asking how many items through that chunk of memory are needed when indices\n",
    "    #    i,j,k,l are incremented by one\n",
    "    strides = img.itemsize * np.array([Y, 1, Y, 1])\n",
    "    return np.lib.stride_tricks.as_strided(img, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da050bf",
   "metadata": {
    "id": "fykjrxzelZoi"
   },
   "source": [
    "GABOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27f0bc5b",
   "metadata": {
    "id": "ferxZyIilZPT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from scipy import misc\n",
    "import scipy.io as sio\n",
    "from skimage.color import rgb2gray\n",
    "def get_gabor(image):\n",
    "    \n",
    "    input_img = image\n",
    "    if input_img.ndim == 3 and input_img.shape[-1] == 3:\n",
    "        img = cv2.cvtColor(input_img,cv2.COLOR_BGR2GRAY)\n",
    "    elif input_img.ndim == 2:\n",
    "        img = input_img\n",
    "    else:\n",
    "        raise Exception(\"The module works only with grayscale and RGB images!\")\n",
    "    pixel_values = image.reshape(-1)\n",
    "    Pixel_Value = pixel_values   #Pixel value itself as a feature\n",
    "    #df['Image_Name'] = image   #Capture image name as we read multiple images\n",
    "    num = 1  #To count numbers up in order to give Gabor features a lable in the data frame\n",
    "    kernels = []  #Create empty list to hold all kernels that we will generate in a loop\n",
    "    for theta in range(8):   #Define number of thetas. Here only 2 theta values 0 and 1/4 . pi \n",
    "        theta = theta / 4. * np.pi\n",
    "        for sigma in (1, 3,):  #Sigma with values of 1 and 3\n",
    "            for lamda in np.arange(0, np.pi, np.pi / 4):   #Range of wavelengths\n",
    "                for gamma in (0.05, 0.5):   #Gamma values of 0.05 and 0.5\n",
    "                           \n",
    "                    gabor_label = 'Gabor' + str(num)  #Label Gabor columns as Gabor1, Gabor2, etc.\n",
    "                    #print(gabor_label)\n",
    "                    ksize=9  #Try 15 for hidden image. Or 9 for others\n",
    "                    phi = 0  #0.8 for hidden image. Otherwise leave it to 0\n",
    "                    kernel = cv2.getGaborKernel((ksize, ksize), sigma, theta, lamda, gamma, phi, ktype=cv2.CV_32F)    \n",
    "                    kernels.append(kernel)\n",
    "                    #Now filter the image and add values to a new column \n",
    "                    fimg = cv2.filter2D(image, cv2.CV_8UC3, kernel)                \n",
    "                    filtered_img = fimg.reshape(-1)\n",
    "                \n",
    "                    gabor_label = filtered_img  #Labels columns as Gabor1, Gabor2, etc.\n",
    "                    #print(gabor_label, ': theta=', theta, ': sigma=', sigma, ': lamda=', lamda, ': gamma=', gamma)\n",
    "                    num += 1  #Increment for gabor column label\n",
    "    return gabor_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a21c142",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11361,
     "status": "ok",
     "timestamp": 1647586488922,
     "user": {
      "displayName": "วงศกร กองกะมุด",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10058041215998170645"
     },
     "user_tz": -420
    },
    "id": "l-8vh5-lennf",
    "outputId": "b493aa82-de91-4fd2-c0e6-070215d289b9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thanawin\\AppData\\Local\\Temp\\ipykernel_14832\\4176593218.py:47: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if lbp_featured == \"error\":\n"
     ]
    }
   ],
   "source": [
    "#features_HOG,labels_HOG = feat_lab_HOG(imagePaths)\n",
    "#features_LAND,labels_LAND = feat_lab_LAND(imagePaths)\n",
    "features_LBP,labels_LBP = feat_lab_LBP(imagePaths)\n",
    "#features_HLAC,labels_HLAC = feat_lab_HLAC(imagePaths)\n",
    "#features_GABOR,labels_GABOR = feat_lab_GABOR(imagePaths) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e82cc9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1647586496246,
     "user": {
      "displayName": "วงศกร กองกะมุด",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "10058041215998170645"
     },
     "user_tz": -420
    },
    "id": "bapIjN8FhVzn",
    "outputId": "58f3e990-3b82-4978-a277-fecb86d4d801"
   },
   "source": [
    "### print(\"LAND: \",features_LAND)\n",
    "print(\"HOG: \",features_HOG)\n",
    "print(\"LBP: \",features_LBP)\n",
    "print(\"HLAC: \",features_HLAC)\n",
    "print(\"GABOR\",features_GABOR)\n",
    "\n",
    "#print(\"LAND: \",features_LAND.shape)\n",
    "print(\"HOG: \",features_HOG.shape)\n",
    "print(\"LBP: \",features_LBP.shape)\n",
    "print(\"HLAC: \",features_HLAC.shape)\n",
    "print(\"GABOR\",features_GABOR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6023fab",
   "metadata": {
    "id": "YuCKPVSJ0mzh"
   },
   "source": [
    "# SAVE FILE ด้วย"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce4cdd3a",
   "metadata": {
    "id": "WqnlbL59yEMm"
   },
   "outputs": [],
   "source": [
    "#np.save(\"features_HOG\", features_HOG)\n",
    "#np.save(\"features_HLAC\", features_HLAC)\n",
    "#np.save(\"features_LAND\", features_LAND)\n",
    "np.save(\"features_LBP\", features_LBP)\n",
    "#np.save(\"features_GABOR\", features_GABOR)\n",
    "\n",
    "\n",
    "#np.save(\"labels_HOG\", labels_HOG)\n",
    "#np.save(\"labels_HLAC\", labels_HLAC)\n",
    "#np.save(\"labels_LAND\", labels_LAND)\n",
    "np.save(\"labels_LBP\", labels_LBP)\n",
    "#np.save(\"labels_GABOR\", labels_GABOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd09d2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n"
     ]
    }
   ],
   "source": [
    "print(123)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Extract_Feature.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
