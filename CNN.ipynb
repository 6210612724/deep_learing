{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2864def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices())\n",
    "tf.config.experimental.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7112f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    #for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from tensorflow.keras.applications import VGG16, InceptionResNetV2\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de92226d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dir = r\"C:\\Users\\thanawin\\Desktop\\Deep\\detect\\train\" #passing the path with training images\n",
    "test_dir = r\"C:\\Users\\thanawin\\Desktop\\Deep\\detect\\test\"   #passing the path with testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "639e11cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128 #original size of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52485c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(#rotation_range = 180,\n",
    "                                         width_shift_range = 0.1,\n",
    "                                         height_shift_range = 0.1,\n",
    "                                         horizontal_flip = True,\n",
    "                                         rescale = 1./255,\n",
    "                                         #zoom_range = 0.2,\n",
    "                                         validation_split = 0.2\n",
    "                                        )\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                         validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5122c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16364 images belonging to 7 classes.\n",
      "Found 452 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory = train_dir,\n",
    "                                                    target_size = (img_size,img_size),\n",
    "                                                    batch_size = 64,\n",
    "                                                    color_mode = \"grayscale\",\n",
    "                                                    class_mode = \"categorical\",\n",
    "                                                    subset = \"training\"\n",
    "                                                   )\n",
    "validation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n",
    "                                                              target_size = (img_size,img_size),\n",
    "                                                              batch_size = 64,\n",
    "                                                              color_mode = \"grayscale\",\n",
    "                                                              class_mode = \"categorical\",\n",
    "                                                              subset = \"validation\"\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "623bbd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 60\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d94a4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thanawin\\.conda\\envs\\py2\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model= tf.keras.models.Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(128, 128,1)))\n",
    "model.add(Conv2D(64,(3,3), padding='same', activation='relu' ))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128,(5,5), padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(512,(3,3), padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "    \n",
    "model.add(Dense(512,activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(\n",
    "    optimizer = Adam(lr=0.0001), \n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6e6fc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 64)      256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               8388864   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 11,705,863\n",
      "Trainable params: 11,701,895\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea64d40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "256/256 [==============================] - 225s 772ms/step - loss: 8.9070 - accuracy: 0.3195 - val_loss: 9.9483 - val_accuracy: 0.1372\n",
      "Epoch 2/60\n",
      "256/256 [==============================] - 51s 199ms/step - loss: 7.6984 - accuracy: 0.4349 - val_loss: 9.7862 - val_accuracy: 0.1571\n",
      "Epoch 3/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 6.6233 - accuracy: 0.4914 - val_loss: 9.5359 - val_accuracy: 0.1327\n",
      "Epoch 4/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 5.6319 - accuracy: 0.5378 - val_loss: 8.3400 - val_accuracy: 0.2389\n",
      "Epoch 5/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 4.7618 - accuracy: 0.5769 - val_loss: 5.6271 - val_accuracy: 0.272169 - ETA:  - ETA: 25s - loss: 4.9527 - a - ETA: 22s -  - ETA: 16s - loss: 4.8763 - accura - ETA: 14s - loss: 4.8657 - accuracy: 0 - ETA: 13s - loss: 4.8583 - a - ETA: 10s - loss: 4.8379 - ac\n",
      "Epoch 6/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 4.0155 - accuracy: 0.6060 - val_loss: 5.3873 - val_accuracy: 0.2876 43s - loss: 4.3043 - accuracy: 0.58 - ETA: 43s - loss: 4.3007 - accuracy: 0 - ETA: 42s - loss: 4.2930 - accur - ETA: 39s - loss: 4.2750 - accuracy: 0. - ETA - ETA: 31s - loss: 4.2205 - ETA: 27s - loss: 4.2034 - accuracy: 0.5 - ETA: 26s - loss: 4.2006 - a - ETA: 23s - loss: 4.1800 - accuracy: 0.59 - ETA: 23s - loss: 4.1775 - ac - ETA: 20s - loss: 4.1509 - ac - ETA: 18s - loss: 4.1340 - accuracy: 0. - ETA: 17s - loss: 4.1290 - accuracy: 0.60 -  - ETA: 0s - loss: 4.0184 - accuracy: 0.60 - ETA: 0s - loss: 4.0173 - accuracy: 0.\n",
      "Epoch 7/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 3.4023 - accuracy: 0.6321 - val_loss: 4.4099 - val_accuracy: 0.37396463 - accuracy: 0.626 - ETA: 45s - loss: 3.6405 - accurac - ETA: 34s - loss: 3.5854 - - ETA: 31s - loss: 3.5683 -  - ETA: 28s - loss: 3.5600 - ETA: 24s - loss: 3.5353 - accuracy - ETA:  - ETA: 15s - loss: 3.4845 - accuracy: 0.627 - ETA\n",
      "Epoch 8/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 2.8962 - accuracy: 0.6524 - val_loss: 3.2384 - val_accuracy: 0.4801ETA: 32s - lo - ETA: 26s - loss - ETA: 21s - loss: 2.9906 - accuracy: - ETA: 20s - lo - ETA: 14s - loss: 2.9556 - - ETA: 10s - loss: 2.9468 - accuracy: 0.6 - ETA: 10s - - ETA: 6s - loss: 2.9275 -  - ETA: 5s - loss: 2.918 - ETA: \n",
      "Epoch 9/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 2.4738 - accuracy: 0.6699 - val_loss: 4.0917 - val_accuracy: 0.5000.5530 - accuracy - ETA: 19s - loss: 2.5482 - accuracy: 0 - ETA: 18s - loss: 2.5443 - accuracy: 0 - ETA: 17s - loss: 2.5393 - a - ETA: 14s\n",
      "Epoch 10/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 2.1444 - accuracy: 0.6828 - val_loss: 3.1101 - val_accuracy: 0.4956TA: 16s - loss: 2.1876 - accu - ETA: 14s - loss: 2.1776 - a - ETA: 11s - loss: 2.17 - ETA: 8s - loss: 2.1608 - accuracy: 0.68 - ETA: 8s - loss: 2.1598 - accuracy:  - ETA: \n",
      "Epoch 11/60\n",
      "256/256 [==============================] - 52s 201ms/step - loss: 1.8797 - accuracy: 0.6986 - val_loss: 2.4913 - val_accuracy: 0.4978cy: 0. - ETA: 42s - loss: 1.9934 - a - ETA: 40s - loss: 1.9880 - a - ETA: 36s - loss: 1.982 - ETA: 32s - loss: 1.9577 - accuracy: 0.69 - ETA: 32s - loss: 1.956 - ETA: 28s - loss: 1.9453 - acc - ETA: 25s - loss: - ETA: 20s - loss:  - ETA: 15s - loss: 1.9167 -  - ETA: 12s - loss: 1.9063 -  - ETA: 4s - loss: 1.890 - ETA: 2s -\n",
      "Epoch 12/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 1.6618 - accuracy: 0.7130 - val_loss: 2.6340 - val_accuracy: 0.6173\n",
      "Epoch 13/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 1.4967 - accuracy: 0.7209 - val_loss: 2.1798 - val_accuracy: 0.5420 loss: 1.5234 - ac - ETA: 43s - loss: 1.5295 - accur  - ETA: \n",
      "Epoch 14/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 1.3538 - accuracy: 0.7368 - val_loss: 2.0225 - val_accuracy: 0.54200.74 - ETA: 39s - loss: 1.3733 - ac - ETA: 36s - loss: 1.3737 - accuracy: 0. - ETA: 35s - loss: 1.37 - ETA: 31s - los - ETA: 4s - ETA: 1s - loss: 1.3558 - ac\n",
      "Epoch 15/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 1.2523 - accuracy: 0.7414 - val_loss: 1.5690 - val_accuracy: 0.6460 - loss: 1 - ETA: 13s - loss: 1.2656 - accuracy: 0.7 - ETA: 12s - loss: 1.2629 - a - ETA: 9s - loss: 1.2595 - ac - - ETA: 4s - loss: 1.2578 - accuracy:  - ETA: 3s - loss: 1.2 - ETA: 1s - loss: 1.2545 - \n",
      "Epoch 16/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 1.1626 - accuracy: 0.7581 - val_loss: 1.6821 - val_accuracy: 0.6106\n",
      "Epoch 17/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 1.0848 - accuracy: 0.7647 - val_loss: 1.4217 - val_accuracy: 0.6372817  - ETA: 27s - loss: 1.0831 - - ETA: 23s - loss: 1.0 - ETA: 1 - ETA: 6s - loss: 1.0 - ETA:  - ETA: 0s - loss: 1.0852 - accura\n",
      "Epoch 18/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 1.0276 - accuracy: 0.7726 - val_loss: 1.6223 - val_accuracy: 0.6571: 1 - ETA: 4s - loss: 1.0297 - accura - ETA: \n",
      "Epoch 19/60\n",
      "256/256 [==============================] - 52s 201ms/step - loss: 0.9930 - accuracy: 0.7758 - val_loss: 1.7435 - val_accuracy: 0.6726\n",
      "Epoch 20/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.9472 - accuracy: 0.7819 - val_loss: 1.4778 - val_accuracy: 0.677040s - loss: 0.9168 - accuracy:  - ETA: 39s - loss: 0.9140 - accuracy - ETA: 37s - loss: 0.9160 - accuracy: 0.793 - ETA: 37s - loss: 0.9165 - - ETA: 33s - loss: 0.9197 - accu - ETA: 31s - loss: 0. - ETA: 26s - loss: 0.9402 -  - ETA: 23s - loss: 0.9430 - accur - ETA: 21s - loss: 0.9454 - accur - ETA: 19s - loss - ETA: 14s - loss: 0.9492 - accur - ETA: 11s - loss: 0.9490 - accuracy:  - ETA: - ETA:  - ETA: 2s - loss: 0.946 - ETA: 0s - loss: 0.9459 - accu\n",
      "Epoch 21/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.9135 - accuracy: 0.7914 - val_loss: 1.8609 - val_accuracy: 0.6372\n",
      "Epoch 22/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.8985 - accuracy: 0.7910 - val_loss: 1.7971 - val_accuracy: 0.6527\n",
      "Epoch 23/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.8719 - accuracy: 0.7999 - val_loss: 1.6434 - val_accuracy: 0.68362s - ETA: 3s - loss: 0.8725 - accuracy - ETA: 2s - loss:\n",
      "Epoch 24/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.8484 - accuracy: 0.8010 - val_loss: 1.9219 - val_accuracy: 0.648201 - accuracy: 0 - ETA: 43s - loss: 0.7973 - accuracy: 0.815 - ETA: 43s - loss: 0.79 - ETA: 39s - ETA: 14s - loss: 0.8409  - ETA: 6s - loss: 0.8480 - accuracy: 0.80 - ETA: 5s - loss: 0.847 - ETA:  - ETA: 0s - loss: 0.8477 - accuracy: \n",
      "Epoch 25/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.8369 - accuracy: 0.8068 - val_loss: 1.3948 - val_accuracy: 0.67700. - ETA: 41 - ETA: 34s - loss: 0.8347 - accurac - ETA: 33s - loss: 0.8329 -  - ETA: 29s - loss: 0.8382 - accuracy: 0.80 - ETA: 29s - loss: 0.8387 - acc - ETA: 27s - lo - ETA: 21s - loss: 0.8407 - accuracy - ETA: 19s - loss: 0.8359 - accuracy: 0 - ET - ETA: 1s - loss: 0.8378 - \n",
      "Epoch 26/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.8171 - accuracy: 0.8127 - val_loss: 2.9792 - val_accuracy: 0.4226ETA: 6s - loss: 0.8186 - accuracy: 0. - ETA: 5s - loss: 0.8189  - ETA: 4s - l - ETA: 1s - loss: 0.8176 - ac\n",
      "Epoch 27/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.8119 - accuracy: 0.8164 - val_loss: 1.4018 - val_accuracy: 0.6571- ETA: 12s - loss: \n",
      "Epoch 28/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7977 - accuracy: 0.8167 - val_loss: 1.4058 - val_accuracy: 0.6925y: 0.81 - ETA: 16s - loss: - ETA: 6s - loss: 0.7991  - ETA: 4s - loss: 0.8003  - ETA: 2s - l\n",
      "Epoch 29/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7795 - accuracy: 0.8236 - val_loss: 1.5719 - val_accuracy: 0.5863\n",
      "Epoch 30/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7642 - accuracy: 0.8281 - val_loss: 2.4669 - val_accuracy: 0.4801: 36s - loss: 0.7405 - accuracy: 0. - ETA: 35s - loss: 0.7455 - - ET - E\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7702 - accuracy: 0.8293 - val_loss: 1.4189 - val_accuracy: 0.6549ss: 0 - ETA: 1s - loss: 0.7\n",
      "Epoch 32/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7519 - accuracy: 0.8339 - val_loss: 1.5984 - val_accuracy: 0.59730.7494 - acc - ETA: 9s - loss: 0.748 - ETA: 7s - loss: 0.7503 - accuracy: 0.83 - ETA: 6s - loss: 0.7500 - accuracy: 0. - ETA: 6s - loss: -\n",
      "Epoch 33/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7553 - accuracy: 0.8301 - val_loss: 1.6061 - val_accuracy: 0.681445s - loss: 0.7541 - ac - ETA: 43s - loss: 0.7501 - ETA: 30s - loss: 0.7472 - accurac - ETA: 28s - loss: 0.7511 - accuracy: 0.83 - ETA: 28s - loss: 0.7515 - a - ETA: 25s - loss: 0.7527  - ETA: 2s - loss:\n",
      "Epoch 34/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7434 - accuracy: 0.8365 - val_loss: 1.7676 - val_accuracy: 0.5686ss: 0.7384 - accuracy: 0.8 - ETA: 24s - loss: 0.7382  - ETA: 6s - loss: 0.7410 - accuracy:  - ETA: 6s - loss: 0.741\n",
      "Epoch 35/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7543 - accuracy: 0.8341 - val_loss: 1.4326 - val_accuracy: 0.7367\n",
      "Epoch 36/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7306 - accuracy: 0.8407 - val_loss: 1.2635 - val_accuracy: 0.7301 ETA: 41s - loss: 0.7401 - ac - ETA: 38s - loss: 0.7326 - accur - ETA: 36s - loss: 0.7305 - ac - ETA: 33s - loss: 0.7267 - accuracy: 0. - ETA: 33 - ETA - ETA: 18s - l - ETA: 6s - l - ETA: 3s - loss: 0.7323 - accuracy:  - ETA: 3s\n",
      "Epoch 37/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7261 - accuracy: 0.8459 - val_loss: 1.6319 - val_accuracy: 0.688147s - loss: 0.7160 - accuracy: 0.8 - ETA: 46s - loss: 0.7300 - accuracy: - ETA: 45s - loss: 0.7329 - accur - ETA: 42s - loss: 0.7281 - accuracy: 0.843 - ETA: 42s - loss: 0.7241 - accuracy: 0. - ETA: 41s - loss: 0.7293 - accuracy:  - ETA: 40s - loss: 0.7262 - acc - ETA: 38s - loss: 0.7244 - accuracy: 0 - ETA: 37s - - ETA: 30s - loss: 0.7194 - accur - ETA: 19s - loss: 0.7224 - accuracy: 0.844 - ETA: 19s - loss:  - ETA: 7s - ETA: 0s - loss: 0.7261 - accuracy: 0.84\n",
      "Epoch 38/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7283 - accuracy: 0.8421 - val_loss: 1.1192 - val_accuracy: 0.7367 25s - loss: 0.7209 - accu - ETA: 22s - loss: 0.71 - ETA: 18s - loss: 0.7153 - - ETA: 15s - loss: 0.7178 - a - ETA: 12s - loss: 0.7235 - accura - ETA: 10s - l - ETA: 7s - loss: 0.7287 - ac - ETA: 5s - loss: 0.7289 - \n",
      "Epoch 39/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7164 - accuracy: 0.8486 - val_loss: 1.5330 - val_accuracy: 0.7080s: 0.7120 - accura - ETA: 7s - loss: 0 - ETA: 5s - - ETA: 2s - loss: 0\n",
      "Epoch 40/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7148 - accuracy: 0.8504 - val_loss: 1.5917 - val_accuracy: 0.6438 accuracy: 0.8 - ETA: 34s - l - ETA: 28s - loss: 0.7141 - ETA: 24s - loss: 0.7194 - ETA: 2 - ETA: 13s -\n",
      "Epoch 41/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7174 - accuracy: 0.8502 - val_loss: 1.2153 - val_accuracy: 0.6858 - loss: 0.7115 - accuracy: 0.85 - ETA: 48s - loss: 0.6955 - accuracy: 0.86 - ETA: 47s - loss: 0. - ETA: 43s - loss: 0.67 - ETA: 39s - loss: 0.6757 - accu - ETA: 36s - loss: 0.6837 - accura - ETA: 34s - loss: 0.6938 - acc - ET - ETA: 24s - loss: 0.7082 - accuracy:  - ETA: 23s - loss: 0.7083 - accu - ETA: 20s - loss: 0.7086 - accuracy - ETA: 19s - loss: 0.7077 - acc - ETA:  - ETA: 0s - loss: 0.7173 - accura\n",
      "Epoch 42/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6997 - accuracy: 0.8543 - val_loss: 1.7071 - val_accuracy: 0.62835 - accura - ETA: 38s - loss: 0.7035 - a - ETA: 35s - loss: 0.7030 - accura -   - ETA: 16s - loss: 0.7000 - acc - ETA: 13s - loss: 0.7013 - a - ETA: 10s - loss: 0.7 - ETA: 8s - loss: 0.7003 - accuracy: 0. - - ETA: 3s - loss: 0.6989  - ETA: 1s - loss: 0.699\n",
      "Epoch 43/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.7139 - accuracy: 0.8530 - val_loss: 1.2540 - val_accuracy: 0.7190\n",
      "Epoch 44/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6917 - accuracy: 0.8621 - val_loss: 1.5403 - val_accuracy: 0.6991ccuracy:  - ETA: 13 - ETA: 8s - loss: 0.6926  - ETA: 6s - loss: 0\n",
      "Epoch 45/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6866 - accuracy: 0.8599 - val_loss: 1.1764 - val_accuracy: 0.6991 0.85 - ETA: 34s - loss: 0.6879 - accura - ETA: 32s - loss: 0.6918 - accurac - ETA: 31s - loss: 0.6909 - accuracy: 0.8 - ETA: 30s - loss: 0.6914 - acc - ETA: 27s - loss: 0.6894 - ETA: 24s - loss: 0.6870 - a - ETA: 21s - loss: 0.6832  - ETA: 17s - loss: 0.6882 - accuracy: 0. - ETA: 16s - loss: 0.6888 - accuracy: 0 - ETA: 15s - lo - ETA - ETA: 6s - loss: 0.682\n",
      "Epoch 46/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6842 - accuracy: 0.8602 - val_loss: 2.6061 - val_accuracy: 0.5531\n",
      "Epoch 47/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6750 - accuracy: 0.8644 - val_loss: 1.1363 - val_accuracy: 0.74782 - a - ETA: 41s - loss: - ETA: 36s - loss: 0 - ETA: 31s -  - ETA: 25s - los - ETA: 10s - loss: 0.6648 - acc - ETA: 9s - ETA: 1s - loss: 0.6739 - \n",
      "Epoch 48/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6757 - accuracy: 0.8648 - val_loss: 1.3005 - val_accuracy: 0.7058- acc - ET - ETA: 28s - loss: 0.6773 - accuracy: 0.8 - ETA: 28s - loss: 0.6 - ETA: 23s - loss: 0.6793 - accuracy: 0 - ETA: 7s - loss: 0.673 - ETA: 5s - loss: 0.6731 - ac\n",
      "Epoch 49/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6628 - accuracy: 0.8676 - val_loss: 1.5788 - val_accuracy: 0.5951\n",
      "Epoch 50/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6660 - accuracy: 0.8679 - val_loss: 1.1647 - val_accuracy: 0.7323\n",
      "Epoch 51/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6760 - accuracy: 0.8675 - val_loss: 1.1198 - val_accuracy: 0.7080- - ETA: 19s - loss: 0.6742 - accuracy: 0 - ETA: 18s - loss: 0.6743 - accuracy: - ETA: 17s - loss: 0.67 - ETA: 13s - loss: 0.6752 - accuracy: 0.8 - ETA: 6s - l - ETA: 3s - loss: 0.6753 - ac - ETA: 2s - los\n",
      "Epoch 52/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6734 - accuracy: 0.8701 - val_loss: 1.6189 - val_accuracy: 0.6018- ETA: 0s - loss: 0.6726 - accuracy\n",
      "Epoch 53/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6792 - accuracy: 0.8721 - val_loss: 1.1940 - val_accuracy: 0.7389  - ETA: 1\n",
      "Epoch 54/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6655 - accuracy: 0.8752 - val_loss: 2.2260 - val_accuracy: 0.6615 49s - loss: 0.6411 - accuracy: - ETA: 48 - ETA: 41s - loss: 0.6595 - accuracy:  - ETA: 40s - loss: 0.6576 - acc - ETA: 37s - loss: 0.6512 - - ETA: 34s - loss: 0.6576 - accura - ETA: 32s - lo - ETA: 26s - loss: 0.6558 - accuracy:  - ETA: 25s - loss: 0.6561 - accuracy: 0.87 -\n",
      "Epoch 55/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6717 - accuracy: 0.8719 - val_loss: 1.3048 - val_accuracy: 0.70130.8 - ETA: 34s - loss: 0.6434 - accuracy: 0.880 - ETA: 34s - loss: 0.6449 - accuracy: 0.87 - ETA: 34s - loss: 0.64 - ETA: 29s - loss: 0.6525 - accuracy: 0.877 - ETA: 29s - loss: 0.65 - ETA: 4s - loss: 0.6699 - accuracy: 0.87 - ETA: 4s - loss: 0.6699 - accura - ETA: 3s\n",
      "Epoch 56/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6732 - accuracy: 0.8711 - val_loss: 1.0459 - val_accuracy: 0.7478s: 0.6699 - accura - ETA: 33s - loss: 0.6695 - accuracy: 0.87 - ETA: 33s  - ETA: 17s - loss: 0.6719 - ETA: 1\n",
      "Epoch 57/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6575 - accuracy: 0.8765 - val_loss: 1.3820 - val_accuracy: 0.7168\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6644 - accuracy: 0.8737 - val_loss: 1.0042 - val_accuracy: 0.7611accu - ETA: 32s - loss: 0.6621 - ac - ETA: 21s - loss: 0.6635 - accuracy: 0 - ETA: 20s - loss: 0.6622 - acc - ETA: 17s - loss: 0.6604 - accuracy: 0.87 - ETA: 17s - loss: - ETA: 12s - loss: 0.\n",
      "Epoch 59/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6472 - accuracy: 0.8832 - val_loss: 1.3511 - val_accuracy: 0.72129 - accuracy - ETA: 32s - ETA: 26s - loss: 0.6398 - accuracy - ETA: 24s - loss: 0.6404  - ETA: 12s - loss: 0.6477  - ETA: 0s - loss: 0.6460 - accuracy\n",
      "Epoch 60/60\n",
      "256/256 [==============================] - 51s 200ms/step - loss: 0.6442 - accuracy: 0.8784 - val_loss: 1.3882 - val_accuracy: 0.7146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = train_generator,epochs = epochs,validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7f5230",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
